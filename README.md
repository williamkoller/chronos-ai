# ğŸ¤– CHRONOS AI - Intelligent Time Orchestrator

AI-powered task scheduling system que aprende seus padrÃµes de produtividade e otimiza sua agenda usando **IA Local**.

## âœ¨ Features

- **ğŸ§  IA Local**: Usa Ollama com modelos como Llama 3.2 para agendamento inteligente
- **ğŸ“Š AnÃ¡lise de PadrÃµes**: Analisa automaticamente seus padrÃµes de produtividade
- **ğŸ”„ Melhoria ContÃ­nua**: Aprende com feedback para aprimorar sugestÃµes
- **ğŸ“± MÃºltiplas Interfaces**: API, Dashboard Web e Mobile (em breve)
- **ğŸ”Œ IntegraÃ§Ã£o Notion**: IntegraÃ§Ã£o perfeita com seu workflow existente
- **ğŸ  100% Local**: Sem dependÃªncias de APIs externas caras

## ğŸ—ï¸ Arquitetura

```
chronos-ai/
â”œâ”€â”€ ğŸ“ core/              # Motor de agendamento principal
â”œâ”€â”€ ğŸ“ integrations/      # Clientes API (Notion, IA Local)
â”œâ”€â”€ ğŸ“ learning/          # AnÃ¡lise de padrÃµes e processamento de feedback
â”œâ”€â”€ ğŸ“ api/              # Endpoints REST API
â”œâ”€â”€ ğŸ“ dashboard/        # Dashboard web Streamlit
â”œâ”€â”€ ğŸ“ docker-compose.yml # OrquestraÃ§Ã£o completa com Ollama
â””â”€â”€ ğŸ“ scripts/          # Scripts de teste e configuraÃ§Ã£o
```

## ğŸš€ Quick Start

### **MÃ©todo 1: Docker (Recomendado)**

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/yourusername/chronos-ai
cd chronos-ai

# 2. Configure ambiente
cp .env.example .env
# Edite .env com seu token do Notion

# 3. Inicie tudo com Docker
docker-compose up -d

# 4. Configure modelos IA (automÃ¡tico na primeira execuÃ§Ã£o)
# Ollama irÃ¡ baixar llama3.2:3b automaticamente
```

### **MÃ©todo 2: Local Development**

```bash
# 1. Instale dependÃªncias
pip install -r requirements.txt

# 2. Inicie Ollama localmente
docker run -d -p 11434:11434 --name ollama ollama/ollama
docker exec ollama ollama pull llama3.2:3b

# 3. Configure .env
cp .env.example .env
# Adicione NOTION_TOKEN e DATABASE_ID

# 4. Teste a integraÃ§Ã£o
python test_ai_integration.py

# 5. Inicie API
python api/main.py
```

## ğŸ”§ ConfiguraÃ§Ã£o

### **ConfiguraÃ§Ã£o AutomÃ¡tica (.env)**

```bash
# Notion Configuration
NOTION_TOKEN=ntn_seu_token_aqui
DATABASE_ID=sua_database_id_aqui

# IA Local Configuration (Ollama)
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=llama3.2:3b

# Database Configuration
DB_PASSWORD=sua_senha_postgres
```

### **Setup Notion**

```bash
# Execute o script de configuraÃ§Ã£o automÃ¡tica
python setup_notion_database.py

# Ou configure manualmente:
# 1. Crie integraÃ§Ã£o em https://developers.notion.com
# 2. Compartilhe database com a integraÃ§Ã£o
# 3. Execute verificaÃ§Ã£o:
python check_properties.py
```

### **VerificaÃ§Ã£o de IA Local**

```bash
# Teste completo da IA
python test_local_ai.py

# Teste de integraÃ§Ã£o
python test_ai_integration.py

# Setup automÃ¡tico de modelos
python setup_ollama_models.py
```

## ğŸ“Š Acesso aos ServiÃ§os

ApÃ³s `docker-compose up -d`:

- **Dashboard**: http://localhost:8501
- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Ollama API**: http://localhost:11434

## ğŸ“– Usage

### **API Example**

```python
import requests

# Agendar uma tarefa
task_data = {
    "title": "Revisar proposta do projeto",
    "category": "Planning",
    "priority": "High",
    "estimated_time": 90,
    "description": "AnÃ¡lise detalhada da proposta Q2"
}

response = requests.post("http://localhost:8000/schedule/task", json=task_data)
suggestion = response.json()

print(f"Melhor horÃ¡rio: {suggestion['scheduled_time']}")
print(f"ConfianÃ§a IA: {suggestion['confidence']}")
print(f"RaciocÃ­nio: {suggestion['reasoning']}")
```

### **Dashboard Usage**

1. Abra http://localhost:8501
2. Navegue para "Schedule Task"
3. Preencha detalhes da tarefa
4. Receba sugestÃ£o da IA local
5. ForneÃ§a feedback para melhorar futuras sugestÃµes

## ğŸ§  Como Aprende

CHRONOS AI usa mecanismos de aprendizado locais:

1. **AnÃ¡lise de PadrÃµes**: Analisa tarefas concluÃ­das para identificar padrÃµes de produtividade
2. **Processamento de Feedback**: Aprende com suas avaliaÃ§Ãµes e aÃ§Ãµes
3. **AdaptaÃ§Ã£o ContÃ­nua**: Ajusta recomendaÃ§Ãµes baseado em novos dados
4. **ConsciÃªncia de Contexto**: Considera fatores como hora do dia, tipo de tarefa, carga de trabalho
5. **IA Local**: Usa modelos Llama para sugestÃµes inteligentes sem APIs externas

## ğŸ”§ Modelos IA DisponÃ­veis

### **Modelos PadrÃ£o**

- **llama3.2:3b** (PadrÃ£o) - RÃ¡pido e eficiente (~2GB)
- **mistral:7b** - EquilÃ­brio qualidade/velocidade (~4GB)
- **codellama:7b** - Especializado em cÃ³digo (~4GB)

### **Trocar Modelo**

```bash
# No .env
OLLAMA_MODEL=mistral:7b

# Ou baixar manualmente
docker exec ollama ollama pull mistral:7b
```

## ğŸ› ï¸ Scripts de ManutenÃ§Ã£o

```bash
# Verificar sistema completo
python test_ai_integration.py

# Configurar Notion automaticamente
python setup_notion_database.py

# Verificar propriedades Notion
python check_properties.py

# Diagnosticar Notion
python integrations/notion_diagnostic.py

# Setup modelos Ollama
python setup_ollama_models.py

# Testar IA local
python test_local_ai.py
```

## ğŸ“Š Analytics

CHRONOS AI fornece analytics detalhados:

- TendÃªncias de produtividade ao longo do tempo
- HorÃ¡rios de pico de performance
- AnÃ¡lise de eficiÃªncia por categoria
- Rastreamento de precisÃ£o de estimativas
- TendÃªncias de feedback
- MÃ©tricas de IA local

## ğŸ”® Roadmap

- [x] ğŸ¤– IA Local com Ollama (100% funcional)
- [x] ğŸ”Œ IntegraÃ§Ã£o Notion completa
- [x] ğŸ“Š Dashboard interativo
- [ ] ğŸ“± App Mobile (iOS/Android)
- [ ] ğŸ“… IntegraÃ§Ã£o Google Calendar
- [ ] ğŸ’¬ Bot Slack/Discord
- [ ] ğŸ¯ Tracking de objetivos
- [ ] ğŸ¤ OtimizaÃ§Ã£o para equipes
- [ ] ğŸŒ Suporte multi-timezone
- [ ] ğŸ§  Modelos IA especializados

## ğŸš¨ Troubleshooting

### **Problemas Comuns**

```bash
# API nÃ£o conecta
docker logs chronos-ai_chronos-api_1

# Ollama nÃ£o responde
docker logs chronos-ai_ollama_1
curl http://localhost:11434/api/tags

# Notion nÃ£o conecta
python test_notion_connection.py

# IA nÃ£o funciona
python test_ai_integration.py
```

### **Reset Completo**

```bash
docker-compose down -v
docker-compose up -d
python setup_ollama_models.py
```

## ğŸ¤ Contributing

1. Fork o repositÃ³rio
2. Crie uma branch feature
3. FaÃ§a suas mudanÃ§as
4. Adicione testes
5. Submeta pull request

## ğŸ“„ License

MIT License - veja arquivo LICENSE para detalhes

## ğŸ†˜ Support

- ğŸ› Issues: GitHub Issues
- ğŸ’¬ DiscussÃµes: GitHub Discussions
- ğŸ“– Docs: README.md (este arquivo)

---

**ğŸ‰ Powered by Local AI - Sem APIs externas, sem custos, 100% privado!**

Made with â¤ï¸ by the CHRONOS AI team
